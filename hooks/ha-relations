#!/usr/bin/env python

import json
import sys
import subprocess
import os
import time
import commands

import utils
import ceph

STORAGEMARKER = '/var/lib/juju/storageconfigured'

# CEPH
DATA_SRC_DST = '/var/lib/mysql'
SERVICE_NAME = utils.get_unit_name().replace('-','/').split('/')[0]
KEYRING = "/etc/ceph/ceph.client.%s.keyring" % SERVICE_NAME
KEYFILE = "/etc/ceph/ceph.client.%s.key" % SERVICE_NAME


config=json.loads(subprocess.check_output(['config-get','--format=json']))


def ha_relation_joined():

    # Checking vip values
    if not 'vip' in config:
        utils.juju_log('WARNING', 'NO Virtual IP was defined, bailing')
        sys.exit(1)

    if config['vip_iface'] == "None" or not config['vip_iface']:
        utils.juju_log('WARNING', 'NO Virtual IP interface was defined, bailing')
        sys.exit(1)

    if config['vip_cidr'] == "None" or not config['vip_cidr']:
        utils.juju_log('WARNING', 'NO CIDR was defined for the Virtual IP, bailing')
        sys.exit(1)

    # Obtain the config values necessary for the cluster config. These
    # include multicast port and interface to bind to.
    corosync_bindiface = config['ha-bindiface']
    corosync_mcastport = config['ha-mcastport']

    # Starting configuring resources.
    init_services = {
            'res_mysqld':'mysql',
        }


    # If the 'ha' relation has been made *before* the 'ceph' relation,
    # it doesn't make sense to make it until after the 'ceph' relation
    # is made
    if not utils.is_relation_made('ceph'):
        utils.juju_log('INFO',
                '*ceph* relation does not exist. Not sending *ha* relation data')
        return
    else:
        utils.juju_log('INFO',
                    '*ceph* relation exists. Sending *ha* relation data')

        block_storage = 'ceph'

        resources = {
                'res_mysql_rbd':'ocf:ceph:rbd',
                'res_mysql_fs':'ocf:heartbeat:Filesystem',
                'res_mysql_vip':'ocf:heartbeat:IPaddr2',
                'res_mysqld':'upstart:mysql',
            }

        resource_params = {
                'res_mysql_rbd':'params name="%s" pool="images" user="%s" secret="%s"' % (
                                config['rbd-name'], SERVICE_NAME, KEYFILE),
                'res_mysql_fs':'params device="/dev/rbd/images/%s" directory="%s" fstype="ext4" op start start-delay="10s"' % (
                                config['rbd-name'], DATA_SRC_DST),
                'res_mysql_vip':'params ip="%s" cidr_netmask="%s" nic="%s"' % (config['vip'],
                                config['vip_cidr'], config['vip_iface']),
                'res_mysqld':'op start start-delay="5s" op monitor interval="5s"',
            }

        groups = {
                'grp_mysql':'res_mysql_rbd res_mysql_fs res_mysql_vip res_mysqld',
            }

        for rel_id in utils.relation_ids('ha'):
            utils.relation_set(rid=rel_id,
                               block_storage=block_storage,
                               corosync_bindiface=corosync_bindiface,
                               corosync_mcastport=corosync_mcastport,
                               resources=resources,
                               resource_params=resource_params,
                               init_services=init_services,
                               groups=groups)


def ha_relation_changed():
    relation_data = utils.relation_get_dict()
    if ('clustered' in relation_data and
        utils.is_leader()):
        utils.juju_log('INFO', 'Cluster configured, notifying other services')
        # Tell all related services to start using
        # the VIP
        for r_id in utils.relation_ids('shared-db'):
            utils.relation_set(rid=r_id,
                           db_host=config['vip'])


def ceph_joined():
    utils.juju_log('INFO', 'Start Ceph Relation Joined')

    ceph_dir = "/etc/ceph"
    if not os.path.isdir(ceph_dir):
        os.mkdir(ceph_dir)
    utils.install('ceph-common')

    utils.juju_log('INFO', 'Finish Ceph Relation Joined')


def ceph_changed():
    utils.juju_log('INFO', 'Start Ceph Relation Changed')

    # TODO: ask james: What happens if the relation data has changed?
    # do we reconfigure ceph? What do we do with the data?
    key = utils.relation_get('key')

    if key:
        # create KEYRING file
        if not os.path.exists(KEYRING):
            ceph.create_keyring(SERVICE_NAME, KEYRING, key)
        # create a file containing the key
        if not os.path.exists(KEYFILE):
            fd = open(KEYFILE, 'w')
            fd.write(key)
            fd.close()
    else:
        sys.exit(0)

    # emit ceph config
    hosts = get_ceph_nodes()
    mon_hosts = ",".join(map(str, hosts))
    conf_context = {
        'auth': utils.relation_get('auth'),
        'keyring': KEYRING,
        'mon_hosts': mon_hosts,
        }
    with open('/etc/ceph/ceph.conf', 'w') as ceph_conf:
        ceph_conf.write(utils.render_template('ceph.conf',
                                              conf_context))

    # Create the images pool if it does not already exist
    (status, output) = commands.getstatusoutput("rados --id %s lspools" % SERVICE_NAME)
    pools = "images" in output
    if not pools:
        utils.juju_log('INFO','Creating image pool')
        ceph.create_image_pool(SERVICE_NAME)

    # Configure ceph()
    configure_ceph()

    # If 'ha' relation has been made before the 'ceph' relation
    # it is important to make sure the ha-relation data is being
    # sent.
    if utils.is_relation_made('ha'):
        utils.juju_log('INFO',
                       '*ha* relation exists. Making sure the ha relation data is sent.')
        ha_relation_joined()
        return
    else:
        utils.juju_log('INFO',
                       '*ha* relation does not exist.')

    utils.juju_log('INFO', 'Finish Ceph Relation Changed')


def configure_ceph():
    utils.juju_log('INFO', 'Start Ceph Configuration')

    block_sizemb = int(config['block-size'].split('G')[0]) * 1024
    image_name = config['rbd-name']
    fstype = 'ext4'
    data_src = DATA_SRC_DST
    blk_device = '/dev/rbd/images/%s' % image_name

    # modprobe the kernel module
    utils.juju_log('INFO','Loading kernel module')
    ceph.modprobe_kernel_module('rbd')


    # configure mysql for ceph storage options
    if not utils.eligible_leader():
        utils.juju_log('INFO','This is not the peer leader. Not configuring RBD.')
        # Stopping MySQL
        if utils.running('mysql'):
            utils.juju_log('INFO','Stopping MySQL...')
            utils.stop('mysql')
        return

    elif utils.eligible_leader():
        # create an image/block device
        (status, output) = commands.getstatusoutput('rbd list --id %s --pool images' % SERVICE_NAME)
        rbd = image_name in output
        if not rbd:
            utils.juju_log('INFO', 'Creating RBD Image...')
            ceph.create_image(SERVICE_NAME, image_name, str(block_sizemb))
        else:
            utils.juju_log('INFO',
                       'Looks like RBD already exists. Not creating a new one.')

        # map the image to a block device if not already mapped.
        (status, output) = commands.getstatusoutput('rbd showmapped')
        mapped = image_name in output
        if not mapped:
            # map block storage
            utils.juju_log('INFO', 'Mapping RBD Image as a Block Device')
            ceph.map_block_storage(SERVICE_NAME, image_name, KEYFILE)
        else:
            utils.juju_log('INFO',
                       'Looks like RBD is already mapped. Not re-mapping.')

        # make file system
        # TODO: What happens if for whatever reason this is run again and
        # the data is already in the rbd device and/or is mounted??
        # When it is mounted already, it will fail to make the fs
        utils.juju_log('INFO', 'Trying to move data over to RBD.')
        if not filesystem_mounted(data_src):
            utils.juju_log('INFO', 'Formating RBD.')
            ceph.make_filesystem(SERVICE_NAME, blk_device, fstype)

            # Stopping MySQL
            if utils.running('mysql'):
                utils.juju_log('INFO','Stopping MySQL before moving data to RBD.')
                utils.stop('mysql')

            # mount block device to temporary location and copy the data
            utils.juju_log('INFO', 'Copying MySQL data to RBD.')
            ceph.place_data_on_ceph(SERVICE_NAME, blk_device, data_src, fstype)

            # Make files be owned by mysql user/pass
            cmd = ['chown', '-R', 'mysql:mysql', data_src]
            subprocess.check_call(cmd)
        else:
            utils.juju_log('INFO',
                       'Looks like data is already on the RBD, skipping...')

        if not utils.running('mysql'):
            utils.start('mysql')

    else:
        return

    utils.juju_log('INFO', 'Finish Ceph Configuration')


def filesystem_mounted(fs):
    return subprocess.call(['grep', '-wqs', fs, '/proc/mounts']) == 0


def get_ceph_nodes():
    hosts = []
    for r_id in utils.relation_ids('ceph'):
        for unit in utils.relation_list(r_id):
            #hosts.append(utils.relation_get_dict(relation_id=r_id,
            #                                     remote_unit=unit)['private-address'])
            hosts.append(utils.relation_get('private-address', unit=unit, rid=r_id))
    return hosts


def cluster_changed():
    utils.juju_log('INFO', 'Begin cluster changed hook.')

    if config['block-size'] == "None":
        utils.juju_log('WARNING', 'NO block storage size configured, bailing')
        return

    utils.juju_log('INFO', 'End install hook.')


hooks = {
    "cluster-relation-changed": cluster_changed,
    "ha-relation-joined": ha_relation_joined,
    "ha-relation-changed": ha_relation_changed,
    "ceph-relation-joined": ceph_joined,
    "ceph-relation-changed": ceph_changed,
}

# keystone-hooks gets called by symlink corresponding to the requested relation
# hook.
arg0 = sys.argv[0].split("/").pop()
if arg0 not in hooks.keys():
    error_out("Unsupported hook: %s" % arg0)
hooks[arg0]()
