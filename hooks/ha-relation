#!/usr/bin/env python

import json
import sys
import subprocess
import os
import utils
import drbd
import time

STORAGEMARKER = '/var/lib/juju/storageconfigured'
DRBD_RESOURCE = 'mysql'
DRBD_DEVICE = '/dev/drbd0'
DRBD_MOUNTPOINT = '/var/lib/mysql'

config=json.loads(subprocess.check_output(['config-get','--format=json']))


def ha_relation_joined():
    # obtain the block device
    block_storage = config['block-storage']
    block_device = config['block-device']

    # Obtain the config values necessary for the cluster config. These
    # include multicast port and interface to bind to.
    corosync_bindiface = config['ha-bindiface']
    corosync_mcastport = config['ha-mcastport']

    if block_storage == "None":
        utils.juju_log('WARNING',
                       'NO block storage configured, not passing HA relation data')
        return
    elif block_storage == "drbd":
        # Obtain resources
        resources = {
                'res_mysql_vip':'ocf:heartbeat:IPaddr2',
                'res_mysql_fs':'ocf:heartbeat:Filesystem',
                'res_mysql_drbd':'ocf:linbit:drbd',
                'res_mysqld':'upstart:mysql',
            }
        resource_params = {
                'res_mysql_vip':'params ip="%s" cidr_netmask="%s" nic="%s"' % (config['vip'],
                                config['vip_cidr'], config['vip_iface']),
                'res_mysql_fs':'params device="%s" directory="%s" fstype="ext3"' % (DRBD_DEVICE, DRBD_MOUNTPOINT),
                'res_mysql_drbd':'params drbd_resource="%s"' % DRBD_RESOURCE,
                'res_mysqld':'op monitor interval=5s',
            }

        init_services = {
                'res_mysqld':'mysql',
            }

        groups = {
                'grp_mysql':'res_mysql_fs res_mysql_vip res_mysqld',
            }

        ms = {
                'ms_drbd_mysql':'res_mysql_drbd meta notify="true" master-max="1" master-node-max="1" clone-max="2" clone-node-max="1"'
            }

        orders = {
                'ord_drbd_before_mysql':'inf: ms_drbd_mysql:promote grp_mysql:start'
            }

        colocations = {
                'col_mysql_on_drbd':'inf: grp_mysql ms_drbd_mysql:Master'
            }

    utils.relation_set(block_storage=block_storage,
                 block_device=block_device,
                 corosync_bindiface=corosync_bindiface,
                 corosync_mcastport=corosync_mcastport,
                 resources=resources,
                 resource_params=resource_params,
                 init_services=init_services,
                 colocations=colocations,
                 orders=orders,
                 groups=groups,
                 ms=ms)


def ha_relation_changed():
    pass


def get_cluster_nodes():
    hosts = []
    hosts.append('{}:6789'.format(utils.get_host_ip()))

    for relid in utils.relation_ids('cluster'):
        for unit in utils.relation_list(relid):
            hosts.append(
                '{}:6789'.format(utils.get_host_ip(
                                    utils.relation_get('private-address',
                                                       unit, relid)))
                )

    hosts.sort()
    return hosts


def get_cluster_leader():
    # Obtains the unit name of the first service unit deploy.
    # e.g. mysql-0
    units = []
    local = units.append(utils.get_unit_name())
    for r_id in utils.relation_ids('cluster'):
        for unit in utils.relation_list(r_id):
            units.append(unit.replace('/','-'))

    return min(unit for unit in units)


def get_drbd_conf():
    cluster_hosts = {}
    # TODO: In MAAS private-address is the *hostname*. We need to set the
    # private address in a relation.
    cluster_hosts[utils.get_unit_hostname()] = utils.unit_get('private-address')
    for r_id in utils.relation_ids('cluster'):
        for unit in utils.relation_list(r_id):
            cluster_hosts[unit.replace('/','-')] = \
                utils.relation_get_dict(relation_id=r_id,
                                  remote_unit=unit)['private-address']

    conf = {
            'block_device': config['block-device'],
            'drbd_device': DRBD_DEVICE,
            'units': cluster_hosts,
                }
    return conf


def emit_drbd_conf():
    # read config variables
    drbd_conf_context = get_drbd_conf()
    # write config file
    with open('/etc/drbd.d/mysql.res', 'w') as drbd_conf:
        drbd_conf.write(utils.render_template('mysql.res',
                                              drbd_conf_context))


def configure_drbd():
    drbd.prepare_drbd_disk(config['block-device'])
    drbd.modprobe_module()

    emit_drbd_conf()
    drbd.create_md(DRBD_RESOURCE)
    drbd.bring_resource_up(DRBD_RESOURCE)

    # Wait for quorum.
    while not drbd.is_quorum_secondary():
        time.sleep(1)
    while not drbd.is_state_inconsistent():
        time.sleep(1)

    if utils.get_unit_name() == get_cluster_leader():
        # clear bitmap
        if drbd.is_quorum_secondary() and drbd.is_state_inconsistent():
            drbd.clear_bitmap(DRBD_RESOURCE)
        # wait for resources to be UpToDate
        while not drbd.is_state_uptodate():
            time.sleep(1)
        # Make leader primary
        if drbd.is_state_uptodate():
            drbd.make_primary(DRBD_RESOURCE)
        # Wait for node to become primary
        while not drbd.is_quorum_primary():
           time.sleep(1)
        # Format DRBD resource
        if drbd.is_quorum_primary():
            drbd.format_drbd_device()

    utils.stop("mysql")
    if utils.get_unit_name() == get_cluster_leader() and drbd.is_quorum_primary():
       drbd.put_on_drbd()
       utils.start("mysql")

    return True


def cluster_changed():
    # Check that we are not already configured
    if os.path.exists(STORAGEMARKER):
        utils.juju_log('INFO',
                       'Block storage already configured, not reconfiguring')
        return

    utils.juju_log('INFO', 'Begin cluster changed hook.')
    if len(get_cluster_nodes()) != 2:
        utils.juju_log('WARNING', 'Not enough nodes in cluster, bailing')
        return

    #TODO:
    # 1. check if block-storage has been set
    # 2. prepare block storage
    # 3. emit DRBD conf??? -- maybe not because we need 2 nodes. Unless we call cluster_changed from cluster relationship.
    if config['block-storage'] == "None":
        utils.juju_log('WARNING', 'NO block storage configured, bailing')
        return
    elif config['block-storage'] == "drbd":
        if config['block-device'] == "None":
            utils.juju_log('WARNING',
                           'NO block-device defined, cannot configure DRBD')
            return
        else:
            storage_configured = configure_drbd()
    elif config['block-storage'] == "ceph":
        # TODO: Add support for ceph
        pass

    if not storage_configured:
        utils.juju_log('WARNING', 'Unable to configure block storage, bailing')
        return

    # TODO: if leader fails, then marker should not be placed on secondary node, nor
    # DRBD should be mounted on both.
    # TODO: probably would be good idea to check that DRBD has been mounted in var/lib/mysql
    # in primary and secondary, that should say it has been successful.
    with open(STORAGEMARKER, 'w') as marker:
        marker.write('done')

    utils.juju_log('INFO', 'End install hook.')

def show_drbd():
    import commands
    (status, output) = commands.getstatusoutput("drbd-overview")
    utils.juju_log('INFO', '############################################################3')
    utils.juju_log('INFO', output)
    utils.juju_log('INFO', '############################################################3')

hooks = {
    # TODO: cluster-relation-departed (remove drbdconfigured file)
    "cluster-relation-changed": cluster_changed,
    "ha-relation-joined": ha_relation_joined,
    "ha-relation-changed": ha_relation_changed,
}

# keystone-hooks gets called by symlink corresponding to the requested relation
# hook.
arg0 = sys.argv[0].split("/").pop()
if arg0 not in hooks.keys():
    error_out("Unsupported hook: %s" % arg0)
hooks[arg0]()
